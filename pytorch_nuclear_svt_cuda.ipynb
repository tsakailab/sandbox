{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_nuclear_svt_cuda.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsakailab/sandbox/blob/master/pytorch_nuclear_svt_cuda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeRc34BqIypb",
        "colab_type": "code",
        "outputId": "6ad8b1ef-14b6-419e-99c4-6037c4f2c999",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "import torch\n",
        "device = torch.device('cpu')\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(torch.cuda.get_device_name(torch.cuda.current_device()))\n",
        "    print(torch.cuda.memory_allocated())\n",
        "    print(torch.cuda.memory_cached())\n",
        "    torch.cuda.empty_cache()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla P4\n",
            "0\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYlu1Qh9BwbE",
        "colab_type": "text"
      },
      "source": [
        "## Backpropable nuclear norm and singular value thresholding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Azte-mfIyuI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_scale = 1e-6\n",
        "class _eigpack(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(_eigpack, self).__init__()\n",
        "\n",
        "    def compute_sv(self, a, rndvec=None, scale=_scale):\n",
        "        if rndvec is None:\n",
        "            #rndvec = torch.ones(a.shape[-1])\n",
        "            rndvec = torch.sort(torch.rand(a.shape[-1], device=device) * scale)[0]\n",
        "        s, v = torch.symeig(torch.matmul(torch.transpose(a,-2,-1),a)+torch.diag(rndvec), eigenvectors=True)\n",
        "        return torch.sqrt(torch.abs(s-rndvec)), v\n",
        "\n",
        "    def svd(self, a, rndvec=None, scale=_scale):\n",
        "        s, v = self.compute_sv(a, rndvec, scale)\n",
        "        u = torch.matmul(torch.matmul(a,v),torch.diag_embed(1./s))\n",
        "        return u, s, v\n",
        "\n",
        "\n",
        "class NuclearLoss(_eigpack):\n",
        "    def __init__(self):\n",
        "        super(NuclearLoss, self).__init__()\n",
        "\n",
        "    def forward(self, a, rndvec=None, scale=_scale):\n",
        "        return torch.sum(self.compute_sv(a, rndvec, scale)[0])\n",
        "\n",
        "\n",
        "class SVT(_eigpack):\n",
        "    def __init__(self, prox=None):\n",
        "        super(SVT, self).__init__()\n",
        "        if prox is None:\n",
        "            self.prox = lambda z, th: z.sign() * (z.abs() - th).max(torch.tensor(0, device=device).float())\n",
        "        else:\n",
        "            self.prox = prox\n",
        "\n",
        "    def forward(self, q, th, rndvec=None, scale=_scale):\n",
        "        u, s, v = self.svd(q, rndvec=rndvec, scale=scale)\n",
        "        return torch.matmul(torch.matmul(u, torch.diag_embed(self.prox(s,th))), torch.transpose(v, -2, -1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IX_l2erCs5p",
        "colab_type": "text"
      },
      "source": [
        "## Operation check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCyGhCYiIyrs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "#D = torch.autograd.Variable(torch.randn(32,40000,60, device=device), requires_grad=True)\n",
        "D = torch.autograd.Variable(torch.randn(2,5,3, device=device), requires_grad=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjYPqQhTp1WF",
        "colab_type": "code",
        "outputId": "ba4c3127-95db-41e0-8ed1-f65416a03eef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "# SVT\n",
        "from time import time\n",
        "t0 = time()\n",
        "svt = SVT().to(device)\n",
        "Dt = svt(D, 1.0)\n",
        "print('done in %.2fms' % ((time() - t0)*1000))\n",
        "\n",
        "# check the singular values\n",
        "print(torch.svd(D)[1])\n",
        "print(torch.svd(Dt)[1])"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done in 9.51ms\n",
            "tensor([[3.4395, 2.1921, 1.1903],\n",
            "        [2.8233, 2.4473, 0.2503]], device='cuda:0', grad_fn=<SvdBackward>)\n",
            "tensor([[2.4395e+00, 1.1921e+00, 1.9035e-01],\n",
            "        [1.8233e+00, 1.4473e+00, 4.1797e-08]], device='cuda:0',\n",
            "       grad_fn=<SvdBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWauWWDE00PZ",
        "colab_type": "code",
        "outputId": "3320ec64-204d-4554-d672-a134807b75f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# nuclear norm and its backprop\n",
        "from time import time\n",
        "t0 = time()\n",
        "loss_nu = NuclearLoss().to(device)\n",
        "loss = loss_nu(D)\n",
        "loss.backward(retain_graph=True)\n",
        "print('done in %.2fms' % ((time() - t0)*1000))\n",
        "print(loss.item())"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done in 3.98ms\n",
            "12.342939376831055\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXUYVFEQ96PA",
        "colab_type": "code",
        "outputId": "d38e8133-4a49-4255-ab11-5d1b5c3ddc85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        }
      },
      "source": [
        "# gradient descent vs. proximal operation\n",
        "#lr = 0.1\n",
        "#print(torch.svd(D - lr * D.grad)[1])\n",
        "#print(lr * torch.svd(Dt)[1])\n",
        "\n",
        "print(D.grad)\n",
        "print(D-Dt)\n",
        "print((D-Dt)/D.grad)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[-0.2418, -1.0418,  0.2763],\n",
            "         [-1.0853, -0.5995,  2.4643],\n",
            "         [ 1.9324,  1.0628,  0.4216],\n",
            "         [ 2.0036, -1.5964,  0.8768],\n",
            "         [-0.1230, -1.9690, -1.3800]],\n",
            "\n",
            "        [[ 0.3074,  2.4197,  0.7118],\n",
            "         [-0.8496,  1.6001, -0.2949],\n",
            "         [-2.6790, -0.0276,  0.3750],\n",
            "         [ 0.9675,  0.6638, -0.2327],\n",
            "         [-0.2654,  0.3788, -2.8656]]], device='cuda:0')\n",
            "tensor([[[-0.0806, -0.3473,  0.0921],\n",
            "         [-0.3618, -0.1998,  0.8214],\n",
            "         [ 0.6441,  0.3543,  0.1405],\n",
            "         [ 0.6679, -0.5321,  0.2923],\n",
            "         [-0.0410, -0.6563, -0.4600]],\n",
            "\n",
            "        [[-0.2431,  0.4898,  0.0691],\n",
            "         [-0.3402,  0.4811, -0.1260],\n",
            "         [-0.5896,  0.2689,  0.2727],\n",
            "         [ 0.1465,  0.0599, -0.1632],\n",
            "         [ 0.0695,  0.2711, -0.8783]]], device='cuda:0',\n",
            "       grad_fn=<SubBackward0>)\n",
            "tensor([[[ 0.3333,  0.3333,  0.3333],\n",
            "         [ 0.3333,  0.3333,  0.3333],\n",
            "         [ 0.3333,  0.3333,  0.3333],\n",
            "         [ 0.3333,  0.3333,  0.3333],\n",
            "         [ 0.3333,  0.3333,  0.3333]],\n",
            "\n",
            "        [[-0.7905,  0.2024,  0.0971],\n",
            "         [ 0.4004,  0.3007,  0.4274],\n",
            "         [ 0.2201, -9.7523,  0.7271],\n",
            "         [ 0.1514,  0.0903,  0.7014],\n",
            "         [-0.2619,  0.7155,  0.3065]]], device='cuda:0',\n",
            "       grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnfruLP9-Cl-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_nuc_prox_backward_cuda.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsakailab/sandbox/blob/master/pytorch_nuc_prox_backward_cuda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeRc34BqIypb",
        "colab_type": "code",
        "outputId": "6614134e-6c29-4de8-fb15-7c41c256cc01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "import torch\n",
        "device = torch.device('cpu')\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(torch.cuda.get_device_name(torch.cuda.current_device()))\n",
        "    print(torch.cuda.memory_allocated())\n",
        "    print(torch.cuda.memory_cached())\n",
        "    torch.cuda.empty_cache()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tesla P4\n",
            "0\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYlu1Qh9BwbE",
        "colab_type": "text"
      },
      "source": [
        "# Nuclear Loss backward with prox (singular value thresholding)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFnnjF-9XmzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soft = lambda z, th: z.sign() * (z.abs() - th).max(torch.tensor(0., device=device))\n",
        "\n",
        "class NuclearLossFunc(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input, lw):\n",
        "        u, s, v = torch.svd(input)\n",
        "        ctx.save_for_backward(input, lw, u, s, v)\n",
        "        return torch.sum(s*lw)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, lw, u, s, v = ctx.saved_tensors\n",
        "        grad_input = grad_output.clone()\n",
        "        svt_input = torch.matmul(torch.matmul(u, torch.diag_embed(soft(s,lw))), torch.transpose(v, -2, -1))\n",
        "        return (input - svt_input) * grad_input, s * grad_input\n",
        "\n",
        "\n",
        "class NuclearLoss(torch.nn.Module):\n",
        "    def __init__(self, lw=torch.tensor(1.0, device=device)):\n",
        "        super(NuclearLoss, self).__init__()\n",
        "        self.fn = NuclearLossFunc.apply\n",
        "        self.lw = torch.nn.Parameter(lw, requires_grad=lw.requires_grad)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.fn(input, self.lw)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IX_l2erCs5p",
        "colab_type": "text"
      },
      "source": [
        "# Demonstration 1: observe gradients\n",
        "### Auto differentiation vs. proximal operation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCyGhCYiIyrs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "#D = torch.autograd.Variable(torch.randn(32,40000,60, device=device), requires_grad=True)\n",
        "D = torch.autograd.Variable(torch.randn(2,3,5, device=device), requires_grad=True)\n",
        "Dr = torch.autograd.Variable(D, requires_grad=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWauWWDE00PZ",
        "colab_type": "code",
        "outputId": "d0455f05-e6ed-4131-9601-e2c92d659d9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "#ll = 0.5 * torch.ones(min(3,5), device=device)\n",
        "ll = torch.tensor(0.9, device=device)\n",
        "print('lambda = \\n', ll)\n",
        "#lw = ll.clone()\n",
        "lw = torch.autograd.Variable(ll, requires_grad=True)\n",
        "lwr = torch.autograd.Variable(ll, requires_grad=True)\n",
        "\n",
        "# l1 norm and its backprop\n",
        "from time import time\n",
        "t0 = time()\n",
        "\n",
        "print(\"Singular values = \\n\", torch.svd(D)[1])\n",
        "nucloss = NuclearLoss(lw=lw)\n",
        "loss = nucloss.forward(D)\n",
        "loss.backward(retain_graph=True)\n",
        "print('done in %.2fms' % ((time() - t0)*1000))\n",
        "print('nuclear loss = ', loss.item())\n",
        "\n",
        "lw_sum_sv = torch.sum(torch.svd(Dr)[1]*lwr)\n",
        "lw_sum_sv.backward(retain_graph=True)\n",
        "print('sum of singular values = ', lw_sum_sv.item())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lambda = \n",
            " tensor(0.9000, device='cuda:0')\n",
            "Singular values = \n",
            " tensor([[4.1567, 2.2873, 0.9343],\n",
            "        [1.8618, 1.6319, 0.8835]], device='cuda:0', grad_fn=<SvdBackward>)\n",
            "done in 29.69ms\n",
            "nuclear loss =  10.580000877380371\n",
            "sum of singular values =  10.580000877380371\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUsY6NjhZ8AD",
        "colab_type": "text"
      },
      "source": [
        "### Prox of L1 norm provides gradients that cut down (sparsify) the data entries by the weight lambda while the autorgad cannot.  Imagine the gradient descent (D$-$D.grad).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXUYVFEQ96PA",
        "colab_type": "code",
        "outputId": "74e0071e-2541-430e-c3fb-d9da2eeeb744",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 803
        }
      },
      "source": [
        "print('data = \\n', D)\n",
        "print('\\n Gradient of nuclear loss w.r.t. data by prox = \\n', D.grad)\n",
        "print('\\n Gradient of nuclear loss w.r.t. lambda = \\n', nucloss.lw.grad)\n",
        "print('\\n data = \\n', Dr)\n",
        "print('\\n Gradient of sum of singular values w.r.t. data by autograd = \\n', Dr.grad)\n",
        "print('\\n Gradient of  sum of singular values w.r.t. lambda = \\n', lwr.grad)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data = \n",
            " tensor([[[ 0.4597,  2.6543, -0.3760, -2.6877,  0.3359],\n",
            "         [ 1.0368,  1.2488,  0.8116, -0.6227, -0.7786],\n",
            "         [ 1.2595, -1.2605,  0.7054,  0.0130, -0.8292]],\n",
            "\n",
            "        [[-0.5750, -0.0742, -0.2057, -0.2931,  1.1085],\n",
            "         [-0.4699, -0.8836,  0.0231,  0.5880,  0.7729],\n",
            "         [ 0.6618, -1.1082, -0.2748, -1.2158,  0.2281]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "\n",
            " Gradient of nuclear loss w.r.t. data by prox = \n",
            " tensor([[[ 0.1343,  0.4073, -0.1847, -0.7558,  0.1441],\n",
            "         [ 0.3162,  0.5459,  0.4681,  0.1578, -0.4098],\n",
            "         [ 0.5640, -0.5660,  0.1616, -0.2912, -0.2462]],\n",
            "\n",
            "        [[-0.3841,  0.1959, -0.1562, -0.3093,  0.6980],\n",
            "         [-0.2111, -0.6371,  0.0626,  0.4933,  0.3160],\n",
            "         [ 0.3578, -0.5563, -0.1278, -0.5932,  0.0642]]], device='cuda:0')\n",
            "\n",
            " Gradient of nuclear loss w.r.t. lambda = \n",
            " tensor(11.7556, device='cuda:0')\n",
            "\n",
            " data = \n",
            " tensor([[[ 0.4597,  2.6543, -0.3760, -2.6877,  0.3359],\n",
            "         [ 1.0368,  1.2488,  0.8116, -0.6227, -0.7786],\n",
            "         [ 1.2595, -1.2605,  0.7054,  0.0130, -0.8292]],\n",
            "\n",
            "        [[-0.5750, -0.0742, -0.2057, -0.2931,  1.1085],\n",
            "         [-0.4699, -0.8836,  0.0231,  0.5880,  0.7729],\n",
            "         [ 0.6618, -1.1082, -0.2748, -1.2158,  0.2281]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "\n",
            " Gradient of sum of singular values w.r.t. data by autograd = \n",
            " tensor([[[ 0.1343,  0.4073, -0.1847, -0.7558,  0.1441],\n",
            "         [ 0.3162,  0.5459,  0.4681,  0.1578, -0.4098],\n",
            "         [ 0.5640, -0.5660,  0.1616, -0.2912, -0.2462]],\n",
            "\n",
            "        [[-0.3867,  0.2045, -0.1583, -0.3164,  0.7025],\n",
            "         [-0.2089, -0.6444,  0.0644,  0.4995,  0.3121],\n",
            "         [ 0.3581, -0.5572, -0.1276, -0.5924,  0.0637]]], device='cuda:0')\n",
            "\n",
            " Gradient of  sum of singular values w.r.t. lambda = \n",
            " tensor(11.7556, device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBdaQDCkxz-O",
        "colab_type": "text"
      },
      "source": [
        "# Demonstration 2: minimize nuclear loss $$\\mbox{Minimize}_X\\|X-D\\|_*$$\n",
        "###Note that NuclearLoss is not differentiable at low-rank matrices in a matrix space, so augograd cannot find the minimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BK74UI5ryYGP",
        "colab_type": "code",
        "outputId": "f6001344-fa81-4619-cb95-f576f8bd1560",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "D = torch.randn(2,3,5, device=device)\n",
        "print('D = \\n', D)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "D = \n",
            " tensor([[[-3.0307, -0.5427,  0.6131,  1.3066, -0.8404],\n",
            "         [ 1.4701, -1.2852, -2.6925,  0.7141, -0.4263],\n",
            "         [ 0.5010, -0.6573,  0.4081,  0.0763, -0.8680]],\n",
            "\n",
            "        [[ 0.9476, -0.1991,  0.2063,  1.0195, -1.8145],\n",
            "         [ 1.5864,  0.1531, -0.3000,  1.6152,  1.7262],\n",
            "         [ 0.3771,  0.5302, -2.4082, -0.6667,  0.8107]]], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXDJCrBRwvG1",
        "colab_type": "code",
        "outputId": "84bd7684-3fad-4c22-e81d-b7ff11ec2a95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#ll = 0.5 * torch.ones(3,5, device=device)\n",
        "ll = 0.5\n",
        "print('lambda = \\n', ll)\n",
        "\n",
        "# Using L1Loss with prox\n",
        "nucloss = NuclearLoss(lw=torch.tensor(ll))\n",
        "X = torch.autograd.Variable(torch.randn(D.shape, device=device), requires_grad=True)\n",
        "optimizer = torch.optim.SGD([X], lr = 1e0)\n",
        "\n",
        "t0 = time()\n",
        "num_iter = 30\n",
        "display_step = 1\n",
        "history_loss_prox = []\n",
        "for iter in range(num_iter):\n",
        "    loss = nucloss(X - D)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward(retain_graph=True)\n",
        "    optimizer.step()\n",
        "    history_loss_prox.append(loss.item())\n",
        "\n",
        "    if (iter+1) % display_step == 0:\n",
        "        print ('[{:3d}/{}]: loss = {:.4f},  '.format(iter+1, num_iter, loss.item()))\n",
        "\n",
        "print('D = \\n', D)\n",
        "print('X = \\n', X)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history_loss_prox)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lambda = \n",
            " 0.5\n",
            "[  1/30]: loss = 10.2600,  \n",
            "[  2/30]: loss = 8.7600,  \n",
            "[  3/30]: loss = 7.2600,  \n",
            "[  4/30]: loss = 5.7600,  \n",
            "[  5/30]: loss = 4.6387,  \n",
            "[  6/30]: loss = 3.8887,  \n",
            "[  7/30]: loss = 3.1387,  \n",
            "[  8/30]: loss = 2.3887,  \n",
            "[  9/30]: loss = 1.7672,  \n",
            "[ 10/30]: loss = 1.2672,  \n",
            "[ 11/30]: loss = 0.7672,  \n",
            "[ 12/30]: loss = 0.2672,  \n",
            "[ 13/30]: loss = 0.0040,  \n",
            "[ 14/30]: loss = 0.0000,  \n",
            "[ 15/30]: loss = 0.0000,  \n",
            "[ 16/30]: loss = 0.0000,  \n",
            "[ 17/30]: loss = 0.0000,  \n",
            "[ 18/30]: loss = 0.0000,  \n",
            "[ 19/30]: loss = 0.0000,  \n",
            "[ 20/30]: loss = 0.0000,  \n",
            "[ 21/30]: loss = 0.0000,  \n",
            "[ 22/30]: loss = 0.0000,  \n",
            "[ 23/30]: loss = 0.0000,  \n",
            "[ 24/30]: loss = 0.0000,  \n",
            "[ 25/30]: loss = 0.0000,  \n",
            "[ 26/30]: loss = 0.0000,  \n",
            "[ 27/30]: loss = 0.0000,  \n",
            "[ 28/30]: loss = 0.0000,  \n",
            "[ 29/30]: loss = 0.0000,  \n",
            "[ 30/30]: loss = 0.0000,  \n",
            "D = \n",
            " tensor([[[-3.0307, -0.5427,  0.6131,  1.3066, -0.8404],\n",
            "         [ 1.4701, -1.2852, -2.6925,  0.7141, -0.4263],\n",
            "         [ 0.5010, -0.6573,  0.4081,  0.0763, -0.8680]],\n",
            "\n",
            "        [[ 0.9476, -0.1991,  0.2063,  1.0195, -1.8145],\n",
            "         [ 1.5864,  0.1531, -0.3000,  1.6152,  1.7262],\n",
            "         [ 0.3771,  0.5302, -2.4082, -0.6667,  0.8107]]], device='cuda:0')\n",
            "X = \n",
            " tensor([[[-3.0307, -0.5427,  0.6131,  1.3066, -0.8404],\n",
            "         [ 1.4701, -1.2852, -2.6925,  0.7141, -0.4263],\n",
            "         [ 0.5010, -0.6573,  0.4081,  0.0763, -0.8680]],\n",
            "\n",
            "        [[ 0.9476, -0.1991,  0.2063,  1.0195, -1.8145],\n",
            "         [ 1.5864,  0.1531, -0.3000,  1.6152,  1.7262],\n",
            "         [ 0.3771,  0.5302, -2.4082, -0.6667,  0.8107]]], device='cuda:0',\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f639c3b28d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nREJORS4iEnL/H2g1Y534cIwtAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXBPlWY2KC26",
        "colab_type": "code",
        "outputId": "448371af-e1c2-45ee-bf3f-154def34c1fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#ll = 0.5 * torch.ones(3,5, device=device)\n",
        "ll = 0.5\n",
        "print('lambda = \\n', ll)\n",
        "\n",
        "# Using sum of abs with autogradient\n",
        "nucloss = lambda x: torch.sum(torch.svd(x)[1]*ll)\n",
        "X = torch.autograd.Variable(torch.randn(D.shape, device=device), requires_grad=True)\n",
        "optimizer = torch.optim.SGD([X], lr = 1e0)\n",
        "\n",
        "t0 = time()\n",
        "num_iter = 30\n",
        "display_step = 1\n",
        "history_loss = []\n",
        "for iter in range(num_iter):\n",
        "    loss = nucloss(X - D)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward(retain_graph=True)\n",
        "    optimizer.step()\n",
        "    history_loss.append(loss.item())\n",
        "\n",
        "    if (iter+1) % display_step == 0:\n",
        "        print ('[{:3d}/{}]: loss = {:.4f},  '.format(iter+1, num_iter, loss.item()))\n",
        "\n",
        "print('D = \\n', D)\n",
        "print('X = \\n', X)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "plt.plot(history_loss_prox)\n",
        "plt.plot(history_loss)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lambda = \n",
            " 0.5\n",
            "[  1/30]: loss = 10.8450,  \n",
            "[  2/30]: loss = 9.3450,  \n",
            "[  3/30]: loss = 7.8450,  \n",
            "[  4/30]: loss = 6.3450,  \n",
            "[  5/30]: loss = 4.9625,  \n",
            "[  6/30]: loss = 4.1064,  \n",
            "[  7/30]: loss = 2.9625,  \n",
            "[  8/30]: loss = 2.5004,  \n",
            "[  9/30]: loss = 1.4625,  \n",
            "[ 10/30]: loss = 1.0142,  \n",
            "[ 11/30]: loss = 0.5947,  \n",
            "[ 12/30]: loss = 0.9053,  \n",
            "[ 13/30]: loss = 0.5947,  \n",
            "[ 14/30]: loss = 0.9053,  \n",
            "[ 15/30]: loss = 0.5947,  \n",
            "[ 16/30]: loss = 0.9053,  \n",
            "[ 17/30]: loss = 0.5947,  \n",
            "[ 18/30]: loss = 0.9053,  \n",
            "[ 19/30]: loss = 0.5947,  \n",
            "[ 20/30]: loss = 0.9053,  \n",
            "[ 21/30]: loss = 0.5947,  \n",
            "[ 22/30]: loss = 0.9053,  \n",
            "[ 23/30]: loss = 0.5947,  \n",
            "[ 24/30]: loss = 0.9053,  \n",
            "[ 25/30]: loss = 0.5947,  \n",
            "[ 26/30]: loss = 0.9053,  \n",
            "[ 27/30]: loss = 0.5947,  \n",
            "[ 28/30]: loss = 0.9053,  \n",
            "[ 29/30]: loss = 0.5947,  \n",
            "[ 30/30]: loss = 0.9053,  \n",
            "D = \n",
            " tensor([[[-3.0307, -0.5427,  0.6131,  1.3066, -0.8404],\n",
            "         [ 1.4701, -1.2852, -2.6925,  0.7141, -0.4263],\n",
            "         [ 0.5010, -0.6573,  0.4081,  0.0763, -0.8680]],\n",
            "\n",
            "        [[ 0.9476, -0.1991,  0.2063,  1.0195, -1.8145],\n",
            "         [ 1.5864,  0.1531, -0.3000,  1.6152,  1.7262],\n",
            "         [ 0.3771,  0.5302, -2.4082, -0.6667,  0.8107]]], device='cuda:0')\n",
            "X = \n",
            " tensor([[[-2.9394, -0.5730,  0.3693,  1.1344, -0.6608],\n",
            "         [ 1.2918, -1.2964, -2.5003,  0.8245, -0.4814],\n",
            "         [ 0.5805, -0.6139,  0.3397, -0.1011, -0.8127]],\n",
            "\n",
            "        [[ 0.9056, -0.3362,  0.1591,  0.8832, -1.7306],\n",
            "         [ 1.6030,  0.0494, -0.2530,  1.6646,  1.7776],\n",
            "         [ 0.3231,  0.4521, -2.3888, -0.7344,  0.7405]]], device='cuda:0',\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f639c118550>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXxU5dn/8c+djYRAWMOasKsUUAgE\nyubConWpIiqoFdS6oFafuvVp7farPu3T9mnV1mrFgqioKJuIirhvqCgQ9iXsIluAALIvWeb6/XGG\nJlCWJDPh5Ey+79crLzJnZq65jsd858w959zHmRkiIhJccX43ICIikVGQi4gEnIJcRCTgFOQiIgGn\nIBcRCbiE0/liDRs2tFatWp3OlxQRCby5c+duN7P0E91/WoO8VatW5OTknM6XFBEJPOfctye7X0Mr\nIiIBpyAXEQk4BbmISMApyEVEAk5BLiIScApyEZGAU5CLiARcMIJ8yRTIec7vLkREqqRgBPmyN+Cj\n30NRgd+diIhUOcEI8qzhcHAnrHzH705ERKqcYAR5236Q1hzmveR3JyIiVU4wgjwuHrr8CNZ8BLs3\n+d2NiEiVEowgBy/ILQQLX/W7ExGRKiU4QV6/DbQ6F+a/DKGQ392IiFQZwQly8L70/O4bWD/T705E\nRKqMYAX59y6HGmneXrmIiABBC/KkmtDpalg6FQ7t8bsbEZEqITBBHgqZ90vX4VB0EJa85m9DIiJV\nRCCC/JdTFnH3K/O8G826QqMOGl4REQkLRJCnpSTy/rKtbNt7CJyDrGGwKQe25frdmoiI704Z5M65\n55xz25xzS0otq++c+8A5tyr8b73KbHJIt0yKQ8br88InA51zLcQlaq9cRISy7ZG/AFx8zLKHgI/M\n7Azgo/DtStOuUS2yW9ZjYs4GzAxSG8JZl8DC8ZpIS0SqvVMGuZnNAHYes3gQMDb8+1jgyij39R+G\nZmeyJn8/89bv8hZkDYcD22HVe5X90iIiVVpFx8gbm1le+PctQOMo9XNCl57TlJpJ8UzK2eAtaNsf\najfV8IqIVHsRf9lpZgbYie53zo1wzuU453Ly8/Mr/Dq1aiRw2dlNeWvhZvYfLoL4BG/+lVXvw568\nUxcQEYlRFQ3yrc65pgDhf7ed6IFmNsrMss0sOz09vYIv57m2eyb7C4qZvjgc3F1u0ERaIlLtVTTI\n3wRuCv9+E/BGdNo5uW4t69GmYSqTcjZ6Cxq0hZZ9vOEVO+GHAhGRmFaWww9fBb4CznLObXTO3Qr8\nGbjQObcKGBi+XemccwzJzmT2up2szd/nLcwaBjvXwPqvT0cLIiJVTlmOWrnezJqaWaKZZZjZGDPb\nYWYDzOwMMxtoZsce1VJpru7anPg4x6S54b3yDoMgqTbM19WDRKR6CsSZnaU1Skum31npvDZ3I0XF\nIUhKhU5XwdLX4fBev9sTETntAhfkAEOyM9m29zAzVoWPgskaDoUHvDAXEalmAhnk/ds3omGtJCbM\nCR9TnpEN6e11cWYRqZYCGeSJ8XFc1TWDj3K3sX3f4ZKJtDbOhvwVfrcnInJaBTLIAYZ0y6AoZEyd\nf2QiresgLkFneopItRPYID+jcW2yWtRlwpzwRFq10uHMi72JtIoL/W5PROS0CWyQA1ybncmqbftY\nsKHURFr7t3mn7YuIVBOBDvLLzmlKSmI8E4+c6dluINRqrOEVEalWAh3ktZMTuTQ8kdbBgmJvIq3O\n18PK92DvVr/bExE5LQId5ABDszPYd7ioZCKtrOFgxZpIS0SqjcAHeY/W9WnVoCYTj8xT3rAdtOil\nibREpNoIfJAfmUhr1jc7Wbd9v7cwaxjsWAUbZvvbnIjIaRD4IAe4umsGcQ4mzQ3vlXe4EhJTNZGW\niFQLMRHkTeokc8FZjZg8dyPFIYMataDT4PBEWvv8bk9EpFLFRJCD96Xn1j2lJ9K6EQr2wbKp/jYm\nIlLJYibI+7dvTIPUJCYemUgrswc0OEPHlItIzIuZIE9KiGNwVnM+zN3KjtITaa3/Crav9rs9EZFK\nEzNBDjC0eyaFxcbUBZu9BZ2vBxevLz1FJKbFVJCf2bg2nTPrMiknPJFW7cZw5g+8k4OKi/xuT0Sk\nUsRUkIP3pefyLXtZtHG3tyBrGOzbCqs/9LcxEZFKEnNBfnnnZiQnxpWc6XnGRZCaruEVEYlZMRfk\nacmJXNqpKW8uODKRViJ0vg5Wvgv7tvndnohI1MVckIN3cea9h4t4b+kWb0HWcAgVwaIJ/jYmIlIJ\nYjLIv9+6Pi3q1yy5OHP6WZDRQxNpiUhMiskgj4tzDM3O4Ku1O1i/44C3MGsY5C+HjTn+NiciEmUx\nGeQAV3fLwDmYfGQirY6DIbGmvvQUkZgTs0HetE4K552RXjKRVnKaNyvikilQsN/v9kREoiZmgxxg\naHYmm3cf4ovV270FXYdDwV5Y9oa/jYmIRFFEQe6cu985t9Q5t8Q596pzLjlajUXDwA6NqFczseSY\n8ha9oH4bTaQlIjGlwkHunGsO/BTINrNOQDxwXbQai4YaCfFcmdWcD5Zu5bv9BSUTaX37JexY43d7\nIiJREenQSgKQ4pxLAGoCmyNvKbqGdMukoDjE1AWbvAWdrwcXBwvG+duYiEiUVDjIzWwT8CiwHsgD\ndpvZ+8c+zjk3wjmX45zLyc/Pr3inFdShWRpnN6/DhDnhibTSmkG7C2HBK5pIS0RiQiRDK/WAQUBr\noBmQ6pwbduzjzGyUmWWbWXZ6enrFO43A0O6ZLN+yl6Wb93gLsobB3jxY87Ev/YiIRFMkQysDgW/M\nLN/MCoEpQO/otBVdV3RuRo2EUhNpnXkx1GwA81/0tzERkSiIJMjXAz2dczWdcw4YAORGp63oqpOS\nyMWdmjB1/iYOFRZDQhKccx2seBf2b/e7PRGRiEQyRj4LmAzMAxaHa42KUl9RNzQ7kz2HSk+kNQxC\nhZpIS0QCL6KjVszsd2bW3sw6mdlwMzscrcairVebBmTUS2FSzkZvQeMO0LwbzHtJE2mJSKDF9Jmd\npcXFOYZ0y+TLNdvZsLP0RFq5sHmev82JiESg2gQ5wNXdmgMweW54r7zT1ZCQ4u2Vi4gEVLUK8ox6\nNenbriGT524kFDJIrgMdBsGS16DggN/tiYhUSLUKcvCuHrRp10FmrtnhLcgaBof3QO5b/jYmIlJB\n1S7IL+rQmDoppSbSatkH6rXSPOUiEljVLsiTE+O5sksz3l26hd0HCiEuztsrX/c57Fzrd3siIuVW\n7YIcvOGVgqIQbyw8MpHWjwDnzb8iIhIw1TLIOzWvQ4emaSUXZ67THNoN8II8VOxvcyIi5VQtgxzg\n2u6ZLN28h6Wbd3sLsobBnk2w5hN/GxMRKadqG+SDujQjKT6u5EzPsy6FlPr60lNEAqfaBnndmklc\n1LExr/97Iq0acM61sPxt2L/D7/ZERMqs2gY5eMMruw8W8mHuVm/BkYm0Fk/ytzERkXKo1kHeu21D\nmtdNKfnSs0knaJblDa9oIi0RCYhqHeTxcY6ru2XwxertbNp10FuYNQy2LoG8Bf42JyJSRtU6yAGG\ndMvADF7790Ra10BCMsx/2d/GRETKqNoHeWb9mvRp14CJORu8ibRS6sL3rvDGyQsP+t2eiMgpVfsg\nB+/qQRu/O8jXa0tNpHVoN+RO87cxEZEyUJADP+jYhNrJCSUTabU6F+q20DHlIhIICnK8ibQGdWnG\nO0u2sPtgeCKtLsPgm8/gu2/9bk9E5KQU5GHXZrfgcFGINxdu9hZ0OTKR1jhf+xIRORUFeVin5mm0\nb1KbSUeGV+pmQtt+MH+cJtISkSpNQR7mnGNodiaLNu4mN2+PtzBrGOzZ6A2xiIhUUQryUq7Mak5i\nvCuZSKv9DyGlno4pF5EqTUFeSv3UJC7q0ITX52/kcFF4Iq2zh3qHIR7Y6Xd7IiLHpSA/xpDsDL47\nUMhHudu8BV2HQ/FhWDje38ZERE5AQX6Mc89Ip2md5JJjypucDRk9YM6zEAr525yIyHEoyI8RH+e4\nplsGM1bmk7c7fIp+j9th5xpYq6sHiUjVE1GQO+fqOucmO+eWO+dynXO9otWYn67plkGo9ERaHQZB\nzYYwZ4y/jYmIHEeke+RPAO+aWXugM5AbeUv+a9kglZ5t6jMxZ6M3kVZCDeh6I6x8B3Zt8Ls9EZGj\nVDjInXN1gPOAMQBmVmBmu6LVmN+GZmeyfucBZq8LH62S/WPv37nP+9eUiMhxRLJH3hrIB553zs13\nzj3rnEuNUl++u6RTU2rXSGDikasH1W0BZ14Mc8dC0WF/mxMRKSWSIE8AugIjzSwL2A88dOyDnHMj\nnHM5zrmc/Pz8CF7u9EpJiufyLs2YviSPPYcKvYXdb4MD22HZG/42JyJSSiRBvhHYaGazwrcn4wX7\nUcxslJllm1l2enp6BC93+g3NzuRQYYhpC/O8BW36Qf223qGIIiJVRIWD3My2ABucc2eFFw0AlkWl\nqyqic0Ydzmxcq+SY8rg46H4rbJgFeYv8bU5EJCzSo1b+CxjnnFsEdAH+GHlLVceRibQWbNhVMpFW\nlx9BQor2ykWkyogoyM1sQXjY5Bwzu9LMvotWY1XF1V0zSE2K56mPV3sLUurB2dd41/Q8GDMH6YhI\ngOnMzlOol5rErX1b8/biPJZu3u0t7HE7FB6ABa/425yICAryMrn13DakJSfwtw9WeQuadtb8KyJS\nZSjIy6BOSiIjzmvDh7lbWbAhPJzS/TZv/pVvPvW1NxERBXkZ3dynNfVqJvL4Byu9BR2v1PwrIlIl\nKMjLqFaNBO48vy0zVuYzZ93OkvlXVkzX/Csi4isFeTnc2KsVDWvV4LH3V3gLNP+KiFQBCvJySEmK\n5+5+bfl67U5mrt5eMv/KvBc1/4qI+EZBXk7X92hB0zrJPPr+CszMO9Nzfz4se9Pv1kSkmlKQl1Ny\nYjz39G/HvPW7+HRlPrTpD/Xb6ExPEfGNgrwChnTLJKNeCo+/vxJzzjsUccPXsGWx362JSDWkIK+A\npIQ47h1wBos37eb9ZVtL5l+ZPdrv1kSkGlKQV9DgrOa0aZjK4++vJFSjruZfERHfKMgrKCE+jnsH\nnsGKrXt5e3GeN7xSeAAWvup3ayJSzSjII3D5Oc04s3Et/vbhSooan+PNv/LlP7RXLiKnlYI8AnFx\njvsHnsna/P28sWAzXPJ/sG8rvPcrv1sTkWpEQR6hH3RsQsdmaTzx0SoKm3SBcx+ABeNgxbt+tyYi\n1YSCPEJxcY4HLjyT9TsPMHnuRjjv59C4E7z1Uziw0+/2RKQaUJBHQf/2jeiSWZcnP1rFYeLhyqfh\nwA545xd+tyYi1YCCPAqcczx40Zls3n2I8bM3eBeeOO+/YfFEyH3L7/ZEJMYpyKOkb7uG9GxTn0ff\nX8G3O/bDuQ9Ck3Ng2v2wf4ff7YlIDFOQR4lzjr9e05k457jr5XkcCsXB4Ge8QxGn/8zv9kQkhinI\noyizfk3+dm1nluXt4eE3l0LjjnDBQ7B0Cix93e/2RCRGKcijrH/7xtzdry3j52xgUs4G6HMfNMuC\naQ/Avm1+tyciMUhBXgkeuPAserdtwG+mLiF32wG48hko2OeNl5v53Z6IxBgFeSWIj3M8cV0WdVIS\nuevluexJawv9fg3Lp8GS1/xuT0RijIK8kqTXrsE/b+jKhu8O8vNJi7Be90BGd3j7Qdi7xe/2RCSG\nKMgrUfdW9fnlJe15d+kWxsxcD1eOhKJD8NZ9GmIRkahRkFeyW/u25uKOTfjTO8uZs68BDPh/sPId\nWDje79ZEJEZEHOTOuXjn3Hzn3LRoNBRrnHP8Zcg5ZNZL4Z5X5rG944+hRS/v9P09eX63JyIxIBp7\n5PcCuVGoE7PSkhN5+oZu7DpQyE8nLKL48qegcD98/pjfrYlIDIgoyJ1zGcBlgC4hfwodmqXxhys7\nMXPNDv42r9i7zue8sbB7o9+tiUjARbpH/nfg50DoRA9wzo1wzuU453Ly8/MjfLlgG5KdyXXdM3nq\nk9XMbHYzWAg+f9zvtkQk4Coc5M65HwLbzGzuyR5nZqPMLNvMstPT0yv6cjHj4Ss60qFpGne9vYN9\nHa6DeS/Crg1+tyUiARbJHnkf4Arn3DpgPNDfOfdyVLqKYcmJ8Ywc1pWQGT/dNAAD+EJ75SJScRUO\ncjP7pZllmFkr4DrgYzMbFrXOYljLBqk8NqQzH+fVYHa9y2DeS7Brvd9tiUhA6Thyn1zUsQl3nN+G\n+zYNoBh0BIuIVFhUgtzMPjWzH0ajVnXy3xedRWbrM5hQ1A+b/zJ8963fLYlIAGmP3EcJ8XE8dX0W\nLydeQ2EICj/9q98tiUgAKch91igtmd/+aCDji/sRt/AVbOc3frckIgGjIK8CerVtAH0fpMjiWDX5\nYb/bEZGAUZBXEcMu7MkXdX5Im01vsmTJQr/bEZEAUZBXEXFxju43/A/FLoF1Ux5m5/4Cv1sSkYBQ\nkFchaY1bsLfTMC4u/pT/fWkaxSHNWS4ip6Ygr2Ia/uAXEJ9Ir03P8+THq/xuR0QCQEFe1dRuQnz3\nW7gq/gve+HgGn62s3hONicipKcirINf3flxCDX6dOo37xs9n866DfrckIlWYgrwqqt0Y1/1WBhR9\nRrPiTfxk3DwKik44U7CIVHMK8qqqz724+BqMavkxCzbs4o/TdREmETk+BXlVVasR9LiN5hum8fPs\nOF6YuY63Fm72uysRqYIU5FVZ73shIZk7D4yid4sUHnptEau37fO7KxGpYhTkVVmtdLjoD8St/YSx\n9hvaJGznrpfncqCgyO/ORKQKUZBXdd1vhRsmk7h3I1MSfk2j7V/zqymLMdPJQiLiUZAHwRkD4fZP\nSKzTlJeS/kyDxaMZ97XmLhcRj4I8KBq0hds+wLW/jN8mjqP2O3ezeF2e312JSBWgIA+SGrVxQ1/k\nYN9fcnnclySNvZTdeWv87kpEfKYgD5q4OFIGPsS6C8fQLJRH3Oh+hNZ85ndXIuIjBXlAtelzNR+d\nO56tRanw0mD4eiToC1CRaklBHmCDBpzPqDNH82FxF3j3IZh6FxRpHnOR6kZBHmDOOX43pCd/rftb\n/uWGwMJXYdZIv9sSkdNMQR5wqTUSGDk8myeKr2FuUndsxqOwf4ffbYnIaaQgjwHtGtXmT1edzUN7\nh2CH92Gf/Z/fLYnIaaQgjxGDujTnyosGML7oAkKzn8W2r/a7JRE5TRTkMeQnF7RlW/YDHLIEVr/6\nM7/bEZHTREEeQ5xz3DuoL180GsYZOz7h7WlT/G5JRE6DCge5cy7TOfeJc26Zc26pc+7eaDYmFeOc\nY8Atj/BdfAOaz/4Dr8/b4HdLIlLJItkjLwIeNLMOQE/gbudch+i0JZFISKlNrUsepkvcGj6ZMoqP\ncrf63ZKIVKIKB7mZ5ZnZvPDve4FcoHm0GpPIJHa9geJGHfl10gTuHTeLWWt1SKJIrIrKGLlzrhWQ\nBcw6zn0jnHM5zrmc/Pz8aLyclEVcPPE/+AONQ1u5J/Vjbhubw5JNu/3uSkQqQcRB7pyrBbwG3Gdm\ne46938xGmVm2mWWnp6dH+nJSHm37Q7uBjGAKGckHufn52Xyzfb/fXYlIlEUU5M65RLwQH2dmOkSi\nKrrw98QV7GV8+88xg2HPziJv90G/uxKRKIrkqBUHjAFyzezx6LUkUdW4A2QNo87isbx6TSN2Hyxk\n+JjZ7NyvybVEYkUke+R9gOFAf+fcgvDPpVHqS6Kp368hPpEzFz/Oszdls2HnAW54dhZbdh/yuzMR\niYJIjlr5wsycmZ1jZl3CP9Oj2ZxESe0m0OdeWDaVnolrePambNbv2M/gp78kN+8/vtYQkYDRmZ3V\nRe//glpN4L1fc267hky6szdmMOSZr5ixUkcTiQSZgry6SEqF/r+BjbNh2Rt0aJbG63f3JqNeCj9+\nYQ4T5+gMUJGgUpBXJ11+BI06woe/g6ICmtZJYdKdvejTriE/f20Rj763AtPl4kQCR0FencTFw0W/\nh+/WwddPA1A7OZExN2VzXfdMnvpkNfdNWMDhomJ/+xSRcknwuwE5zdoNgDMv8fbKD34H/X9LYnwC\nf7rqbDLr1+Sv760gb/chRg3vRt2aSX53KyJloD3y6mjIC9DtZvjy7/DyYNiXj3OOu/u144nrurBg\n/S6uGjmT9TsO+N2piJSBgrw6SkyGy5+AQf+EDbPhX+fBhjmAd6Whl2/7Pjv2FTD46S+Zv/47n5sV\nkVNRkFdnWcPg1vchPhGevwRmjwYzerSuz5Sf9Ca1RgLXj/6ad5ds8btTETkJBXl117Qz3PEZtO0H\n038Gr98BBQdom16LKT/pTfsmadw1bi5jvvjG705F5AQU5AIp9eD6Cd6p/IsmwrMDYccaGtaqwau3\n9+SiDo35/bRlPPzmUopDOjxRpKpRkIsnLg7O/zkMmwx7N8OofrB8OilJ8Tx9Qzdu69uaF2au446X\n5nKgoMjvbkWkFAW5HK3dQBjxGdRvDeOvhw8fId6K+c0PO/DIFR35ePlWrhv1Ndv2asItkapCQS7/\nqV5LuOU96HojfPE4jL0cdm/kpt6tGDU8m1Vb9zH4nzNZtXWv352KCApyOZHEZLjiSRg8CrYsgpF9\nIPctBnZozMQ7elFQHOKqkTOZuWZ7+eoWHoJvZ0LR4ej1Wqk1ozhve+HBSqr5FRQXRq9mwYFKqLm/\nEmtGcaivMmoe3gdzx0IlTn+hIJeT63wt3DED6rWCCcNg2gOc3TiJ13/SmyZpydz03GymzNt46jqh\nYljwKjyV7R3q+FS298VqKFTx3kLFsOAVeLJbuGZ3WDQp8przx5XU/Gd3WDw5sprFRTDvJfhH13DN\nHrDktSjUfDFc8+JwzSmRhUVxkRc4Tx6p+X1Y+nrkNXOeL+nz6Z6wdGqENQsh5zn4R1ZJzWVvRl5z\nzrPwRJeSmrlvRV5z9mivz7d+CpvmVbzWKSjI5dQatIVbP/Cmws0ZA6P7k1H4LZPv6k12y/o8MHEh\nT3y46vgTbpnByvfhmXNh6p1Qsz5c9jgk14Ept3snI63+sHx/MGaw8j14pi9MvQtSG3o1a6TBlNtg\n1Hmw+qPyraMZrHjH++Txxk+gVrpXM6kWvHYrjL4A1nxS/prLp8MzfeDNe7x54S97HBJrwuRbYHQ/\nWPtpBWq+DSN7w5v/BWnNvJoJyTD5x+Gan5W/Zu40GNnLC5w6GV7N+CSYdDOM7g/fzCh/zWVveoE4\n7T5vuO6yx8HFw6Sb4NkBsO6LCtR8I1zzfm/n4rLHwDmYONw72mrdl+WvuXSq96b19oNQv01JzQnD\nYMyF3qeo8tZcMsV7c53+M2h4Btz6IWR0K1+d8r2mnbafbt26mQTcyg/M/tLW7PeNzeY8Z4cLiuz+\nCfOt5S+m2YMTF9jhwuKSx26YY/bcpWa/SzP7e2ezxZPNisP3FxebLZxo9rdO3v0v/NBs49xTv/76\n2WbPXVKq5mtH11wwvlTNy802zStDzVlmYy72nvNEltmSKWahULhmkdmCV80eD9ccO8hs0/xT1/z2\nK7NnL/Ke84+uZkteP7rm/FfMHu/o3f/ilWabF5Sx5oUlNZe+cUzNcWaPdQjXHGyWt+jUNdfNNBs9\nMFyzm9myN4+uOe8ls8e+593/0lVlq/nNF2ajB3jPeTLbLHdaSc2iQrO5L5o92t67/+VrzPIWl6Hm\n52aj+nnPeaqHWe7bx9QcW6rmELMtS05dc+2Mo2sun350zZwXzB49y7t/3LVmW5aWoeZnZv8633vO\nP3uarXivpGYEgBw7SbY6O43TlmZnZ1tOTs5pez2pJHu3eicOrf0EOgzCfvgEf/8ynyc+WkWfdg14\n5pI61P7yT97eU2o6nP8L6HoTJBxnEq6iw95H7xl/gQM7oONg6P9b71NAadtXwUePeB93j9TsdrN3\nVupxaz4Hn/0FDu6EjlfBgN96e1ul5a/0ai6fBqmN4IKHvC94T1RzzhiY8VevZqdrvPnd67c+puYK\n+PARWPE21Grs1cwafvyahYe8j/OfP+pNYHb2EK9mvVZHP27bcq/PFdO9i4P8u+Zx5rwrPARzRsOM\nR+HQbjhnqHd+QL2Wx9TM9fpc+Q7UbgoX/BK63HCCmge9IYLPHwvXvBb6/eo/a25d5vW58l2vZr9f\nQecfnbjmrH95X6Yf2gOdr/MeX7fF0Y/bssSruep9qN0sXPP649csOACz/wWf/w0O7/Ee1+9XUDfz\nP2t++DCs/gDSmpfUjIs/fs1Zz8AXf4eCvd769Pul96nlqJqLwzU/hLQM6P9r77/T8WpWgHNurpll\nn/B+BblUSCgEXz0JH/2P90d79bNM21CD3e/+geviP8YlphDX56fQ626oUfvU9Q7tgZlPwldPQXGB\nF9Ln/wIsBJ/+2RsPTkyB3kdq1ipDzd3hmv/0ambfAuf9HEKFXs35L0FiqncZvJ53lb3ml//waoaK\nwjX/O1zzTzD/Za9m33uh50+8C3qcysFd8OUT8PVIr2b32+C8n3lvHp/+0fseIKlWSZ9lrvl3r6aF\nvJrn/gyKDsInf4KFr0BSbeh7H3z/TkiqWYaa33mBNuuZcM3b4dwHofCAt+4LXvGGt869H3rcUY6a\nf4OvnwEMeozwahbsg0/+CAvHQ3Ia9H0Avn+H9//AqRzY6b1BzBrl3e4R7vPwXq/mogne0N65D3r3\nlbXm54/B7FGA83rpe3+45v963/ck1/G2W/fbvYMFokhBLpVr41x47RbYtQHikwgVFzLeBjI2YQiP\n3nwhZ2fUKV+9vVvhs/+DuS94474WOjowa6WXv8e9W8I1x3p/tKHiowMztWH5a+7J82oeeYMJFXl1\ne9zuBWZqgwrU3Hz0G0yo8OjArHDNUm8wxQUcFZg165e/5u5N4eAeV6om8P0RXuBWqObGkjeDpFpQ\ndAhw0PNOLzBT6pW/5q4Npd5gans1XZz3xtX3vgrWXB9+I3zVe9MqOujV7HkX9LkPUuqWv2YZKMil\n8h3aA+/9yvuDvuAhVham8+Pn57BzfwFP/SiLAd9rXP6a21d7Qw4uzgvbY4dFKmL7am9oJD7Be1M4\ndgijQjVXecMY0ayZv9LrM6FGuGbLUz/nlDVXeH0mJns1jx3CqIhty71tlFgzXDPz1M85Zc1cr88a\ntbyaxw5hVMTWZd7edI3a3lDBF28AAAYjSURBVP9LUam51KuZXMfrM61Z5DVPQkEuvti25xC3jJ3D\nss17eOSKjgzv1crvlkQC61RBrsMPpVI0Sktmwohe9DurEb99Yyl/nJ5LSBNuiVQKBblUmtQaCYy6\nMZsbe7Vk1Iy13P3KPA4V6nqgItGmIJdKFR/neOSKjvzmsu/x7tItXD/6a3bsi+Kp9CKiIJfK55zj\ntnPbMPKGrizbvIfBT8/k3SV5mttcJEoU5HLaXNypKa+O6AnAnS/PY+Djn/Hy199quEUkQjpqRU67\n4pDx7pIt/GvGGhZt3E2D1CRu7NWKG3u1pF7qcc7+FKnmKvXwQ+fcxcATQDzwrJn9+WSPV5BLaWbG\nrG92MmrGWj5evo3kxDiGZmdyW982tGhQhrMCRaqJSgty51w8sBK4ENgIzAGuN7NlJ3qOglxOZOXW\nvYyesZapCzZRHDIu6dSUEee1oXNm5ZwpJxIklRnkvYCHzewH4du/BDCzP53oOQpyOZWtew7x/Jfr\nGDfrW/YeKqJhrSTinAv/eF+cOse/b8eFbzvncH43L3ISY27qXuFPmqcK8uNMIVZmzYENpW5vBL5/\nnAZGACMAWrSIwmnBEtMapyXz0CXtuad/OybO2cCqbfsAIxSCkBkhC0+9TMntUHgqT5GqLCmh8o4t\niSTIy8TMRgGjwNsjr+zXk9hQq0YCt/RtfeoHikhEhx9uAkrPkpMRXiYiIqdRJEE+BzjDOdfaOZcE\nXAe8GZ22RESkrCo8tGJmRc65e4D38A4/fM7MlkatMxERKZOIxsjNbDowPUq9iIhIBegUfRGRgFOQ\ni4gEnIJcRCTgFOQiIgF3Wmc/dM7lA99W8OkNge1RbKcqiLV10vpUfbG2TrG2PnD8dWppZuknesJp\nDfJIOOdyTjbXQBDF2jppfaq+WFunWFsfqNg6aWhFRCTgFOQiIgEXpCAf5XcDlSDW1knrU/XF2jrF\n2vpABdYpMGPkIiJyfEHaIxcRkeNQkIuIBFwggtw5d7FzboVzbrVz7iG/+4mUc26dc26xc26Bcy6Q\n175zzj3nnNvmnFtSall959wHzrlV4X/r+dljeZxgfR52zm0Kb6cFzrlL/eyxPJxzmc65T5xzy5xz\nS51z94aXB3kbnWidArmdnHPJzrnZzrmF4fV5JLy8tXNuVjjvJoSnCT95rao+Rl6RizxXdc65dUC2\nmQX2RAbn3HnAPuBFM+sUXvYXYKeZ/Tn8hlvPzH7hZ59ldYL1eRjYZ2aP+tlbRTjnmgJNzWyec642\nMBe4EriZ4G6jE63TUAK4nZxzDkg1s33OuUTgC+Be4AFgipmNd849Ayw0s5EnqxWEPfIewGozW2tm\nBcB4YJDPPVV7ZjYD2HnM4kHA2PDvY/H+yALhBOsTWGaWZ2bzwr/vBXLxrrMb5G10onUKJPPsC99M\nDP8Y0B+YHF5epm0UhCA/3kWeA7vxwgx43zk3N3xx6ljR2Mzywr9vARr72UyU3OOcWxQeegnMMERp\nzrlWQBYwixjZRsesEwR0Oznn4p1zC4BtwAfAGmCXmRWFH1KmvAtCkMeivmbWFbgEuDv8sT6mmDdm\nV7XH7U5tJNAW6ALkAY/52075OedqAa8B95nZntL3BXUbHWedArudzKzYzLrgXfO4B9C+InWCEOQx\nd5FnM9sU/ncb8DreBowFW8PjmEfGM7f53E9EzGxr+A8tBIwmYNspPO76GjDOzKaEFwd6Gx1vnYK+\nnQDMbBfwCdALqOucO3L1tjLlXRCCPKYu8uycSw1/UYNzLhW4CFhy8mcFxpvATeHfbwLe8LGXiB0J\nvLDBBGg7hb9IGwPkmtnjpe4K7DY60ToFdTs559Kdc3XDv6fgHdCRixfo14QfVqZtVOWPWgEIH070\nd0ou8vy/PrdUYc65Nnh74eBdM/WVIK6Pc+5V4AK8KTe3Ar8DpgITgRZ40xUPNbNAfIF4gvW5AO/j\nugHrgDtKjS9Xac65vsDnwGIgFF78K7wx5aBuoxOt0/UEcDs5587B+zIzHm+neqKZ/U84I8YD9YH5\nwDAzO3zSWkEIchERObEgDK2IiMhJKMhFRAJOQS4iEnAKchGRgFOQi4gEnIJcRCTgFOQiIgH3/wG8\nYzc/1q8+lAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jup6iCVgOeDK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}